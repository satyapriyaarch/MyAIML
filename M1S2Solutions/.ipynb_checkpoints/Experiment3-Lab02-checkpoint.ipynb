{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2\n",
    "## Experiment 3\n",
    "### Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*After completing this exercise please complete the Check For Understanding questions in the LMS*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source\n",
    "In this experiment, we will use the CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They have downloaded and unzipped for you in the directory cifar-10\n",
    "\n",
    "They are in a particular python-specific format called pickle. You need not worry about the format's internals, as the site has given the code needed to read such files. The code is given in the first code block below.\n",
    "\n",
    "**The code returns the contents of each data file as a dictionary**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick look at the data\n",
    "\n",
    "There are 8 files in the cifar-10 directory.\n",
    "\n",
    "batches.meta\n",
    "\n",
    "data_batch_1\n",
    "\n",
    "data_batch_2\t\n",
    "\n",
    "data_batch_3\n",
    "\n",
    "data_batch_4\t\n",
    "\n",
    "data_batch_5\n",
    "\n",
    "readme.html\n",
    "\n",
    "test_batch\n",
    "\n",
    "We will take a peek at these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo,encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'batch_label', b'labels', b'data', b'filenames']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(unpickle(\"classifier/data_batch_1\").keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data** a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "\n",
    "**labels** a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'leptodactylus_pentadactylus_s_000004.png',\n",
       " b'camion_s_000148.png',\n",
       " b'tipper_truck_s_001250.png',\n",
       " b'american_elk_s_001521.png',\n",
       " b'station_wagon_s_000293.png',\n",
       " b'coupe_s_001735.png',\n",
       " b'cassowary_s_001300.png',\n",
       " b'cow_pony_s_001168.png',\n",
       " b'sea_boat_s_001584.png',\n",
       " b'tabby_s_001355.png']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpickle(\"classifier/data_batch_1\")[b'filenames'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 9, 9, 4, 1, 1, 2, 7, 8, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpickle(\"classifier/data_batch_1\")[b'labels'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpickle(\"classifier/data_batch_1\")[b'data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'labels', b'filenames', b'batch_label', b'data']\n",
      "4 10000 (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "test_data = unpickle(\"cifar-10/test_batch\")\n",
    "print(list(test_data.keys())) \n",
    "print(len(test_data), len(test_data[b'labels']), test_data[b'data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'label_names': [b'airplane',\n",
       "  b'automobile',\n",
       "  b'bird',\n",
       "  b'cat',\n",
       "  b'deer',\n",
       "  b'dog',\n",
       "  b'frog',\n",
       "  b'horse',\n",
       "  b'ship',\n",
       "  b'truck'],\n",
       " b'num_cases_per_batch': 10000,\n",
       " b'num_vis': 3072}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpickle(\"cifar-10/batches.meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "Given a query image drawn from the test set, we attempt to find top “relevant” images from the training set\n",
    "using the K-Nearest Neighbour Method we learned earlier. \n",
    "\n",
    "The algorithm is simple, we rank the images present in the training set by their distance from the query images. A\n",
    "retrieved image is considered “relevant” if the class of retrieved image is same as the query\n",
    "image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**  :: Do you think accuracy is a valid metric to evaluate our search engine performance?\n",
    "If Yes, Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information Retrieval experts usually use two very closely related metrics called Pre-\n",
    "cision@k and Recall@k to evaluate their search engine models where k corresponds to\n",
    "the top-k retrievals. Let’s say q is the query, U is number of images in the training\n",
    "set, R is the set of “relevant” images in the training set and T (k) is the retrieved set\n",
    "of images from our algorithm.\n",
    "\n",
    "                $p@k = |T(k) ∩ R|/ |T (k)|$\n",
    "                \n",
    "                $r@k = |T (k) ∩ R| / |R| $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**  :: Compute the precision@k and recall@k for k = 1,3,5,10. (see this and difference from earlier precision here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**  ::  Plot the Precision-Recall Curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**  ::  Does precision increase or decrease as we increase k, what do you expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5**  ::  Is there a way to make recall@k = 1 for every query for some k? What is that value of k?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6**  ::  For real search engines, is finding recall@k feasible? Why or Why not? Is finding precision@k feasible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
