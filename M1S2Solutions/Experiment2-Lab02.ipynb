{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Session 2\n",
    "## Experiment 2\n",
    "###  Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data Source\n",
    "\n",
    "In this experiment, we will use Wisconsin Breast Cancer data to classify it as benign or malignant.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\n",
    "\n",
    "The data has been modified:\n",
    "\n",
    "* The id field has been removed\n",
    "* The diagnosis field has been moved to the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data Attributes\n",
    "\n",
    "Number of instances: 569 \n",
    "\n",
    "Number of attributes: 31 (diagnosis, 30 real-valued input features)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "\ta) radius (mean of distances from center to points on the perimeter)\n",
    "\tb) texture (standard deviation of gray-scale values)\n",
    "\tc) perimeter\n",
    "\td) area\n",
    "\te) smoothness (local variation in radius lengths)\n",
    "\tf) compactness (perimeter^2 / area - 1.0)\n",
    "\tg) concavity (severity of concave portions of the contour)\n",
    "\th) concave points (number of concave portions of the contour)\n",
    "\ti) symmetry \n",
    "\tj) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The mean, standard error, and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features.  For instance, field 1 is Mean Radius, field 11 is Radius SE, field 21 is Worst Radius. All feature values are recoded with four significant digits.\n",
    "\n",
    "The last field is diagnosis: M for Malignant and B for Benign\n",
    "\n",
    "Class distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Reading csv file as we have seen earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "data = pd.read_csv(\"wdbc.data\",header = None)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Splitting dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "picker = list(range(data.shape[0]))\n",
    "random.shuffle(picker)\n",
    "trainMax = int(len(picker) * TRAIN_TEST_RATIO)\n",
    "train = []\n",
    "test = []\n",
    "for pick in picker[:trainMax]:\n",
    "    train.append(list(data.values[pick]))\n",
    "for pick in picker[trainMax:]:\n",
    "    test.append(list(data.values[pick]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Exercise 1** :: Add code for linear discriminator classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Exercise 2** :: Calculate the accuracy on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let us calculate a different metric to analyze our results, called confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A confusion matrix is a table that is often used to \n",
    "describe the performance of a classification model\n",
    "on a set of test data for which the true values are known.\n",
    "\n",
    "The entries in the confusion matrix have the following meaning in the context of our study:\n",
    "\n",
    "* a (True Positive) is the number of correct predictions that an instance is positive,\n",
    "* b (False Positive) is the number of incorrect predictions that an instance is positive,\n",
    "* c (False Negative) is the number of incorrect of predictions that an instance is negative, and\n",
    "* d (True Negative) is the number of correct predictions that an instance is negative.  \n",
    "\n",
    "\n",
    "![alt](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRozZ7IpyD6mTSUREZZ09SbaC-w8_Gae6syq2rKOBl8Az4gKzCU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here M is positive and B is negative; that is we are looking for cancerous cells. So M means it is cancerous that is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def confusionmatrix(actuals, prediction):\n",
    "    TruePositive = sum([int(a == \"M\" and p == \"M\") for a, p in zip(actuals, prediction)])\n",
    "    TrueNegative = sum([int(a == \"B\" and p == \"B\") for a, p in zip(actuals, prediction)])\n",
    "    FalsePositive = sum([int(a == 'B'and p == \"M\") for a, p in zip(actuals, prediction)])\n",
    "    FalseNegative = sum([int(a == 'M'and p == \"B\") for a, p in zip(actuals, prediction)])\n",
    "    return TruePositive, TrueNegative, FalsePositive, FalseNegative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Precision ** -  ratio of correctly predicted positive observations to the total predicted positive observations. \n",
    "\n",
    "** Recall ** - ratio of correctly predicted positive observations to the all observations in actual class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Exercise 3** :: Calculate precision\n",
    "\n",
    "$ p $ = $ tp $ $ / $ ($ tp $ + $ fp $)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Exercise 4** :: Calculate recall \n",
    "\n",
    "$ r $ = $ tp $ $ /$ ( $ tp $ + $fn $ ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Exercise 5** :: Calculate miss rate\n",
    "\n",
    "$ m $ = $ 1 $ $ - $ $ r $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Exercise 6** :: Calculate accuracy and check with earlier accuracy that we computed.\n",
    "\n",
    "$ a $ = ($ tp $ + $ tn $) / ($ tp $ + $ tn $ + $ fp $ + $ fn $ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
