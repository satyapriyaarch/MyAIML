{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1\n",
    "## Experiment 1\n",
    "### Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After finishing this Experiment, please go over to the LMS, and answer the Check For Understanding Questions under Experiment 1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we will use the data set on fruits which we explored earlier and learn how a simple K nearest neighbour classification works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider a simple situation. Given some data about a fruit, we want to label it automatically.\n",
    "\n",
    "Fruits are characterized by \n",
    " * weight in grams as a float\n",
    " * colour as an integer\n",
    "     - 1 $\\rightarrow$ red\n",
    "     - 2 $\\rightarrow$ orange\n",
    "     - 3 $\\rightarrow$ yellow\n",
    "     - 4 $\\rightarrow$ green\n",
    "     - 5 $\\rightarrow$ blue\n",
    "     - 6 $\\rightarrow$ purple\n",
    " * label as a string\n",
    "     - \"A\" $\\rightarrow$ Apple\n",
    "     - \"B\" $\\rightarrow$ Banana\n",
    "     \n",
    "We are given some sample data such as (303, 3, \"A\") meaning the fruit with 303 gram weight, and yellow colour is an apple. A set of such *training examples* is given in “01-train.csv”. This has a small set of 17 **labeled** examples. \n",
    "\n",
    "We are given a set of **test** data where only weight and colour are given,  eg. (373,1). We should design a simple Nearest Neighbour classifier that will find the fruit label. i.e., \"A\" or \"B\", meaning Apple or Banana. \n",
    "\n",
    "We have 102 such testcases. We are also given additional files which have the correct labels for all the 102 test cases. If your predicted label is correct, you have done well!\n",
    "\n",
    "Here are the details of all the files:\n",
    "  * 01-train.csv $\\Rightarrow$ The original input data. \n",
    "    - 18 lines\n",
    "    - the first line is a header\n",
    "    - each of the remaining 17 lines has three pieces of data:\n",
    "       * weight in grams :: float\n",
    "       * colour code :: 1, 2, 3, 4, 5 \n",
    "       * label :: \"A\", \"B\"\n",
    "  * 01-test1.csv $\\Rightarrow$ The first test data set.\n",
    "    - 31 lines\n",
    "    - the first line is a header\n",
    "    - each of the remaining 30 lines has two pieces of data\n",
    "       * weight in grams :: float\n",
    "       * colour code :: 1, 2, 3, 4, 5\n",
    "  * 01-test1-labels.csv $\\Rightarrow$ The labels for test data set above. That is, each line has just the correct label.\n",
    "  * 01-test1-labelled.csv $\\Rightarrow$ The above two files combined. \n",
    "  * 01-test2.csv $\\Rightarrow$ The second test data set. Similar to the first data set, except that it has 73 lines.\n",
    "  * 01-test2-labels.csv $\\Rightarrow$ The labels for test data set above. That is, each line has just the correct label.\n",
    "  * 01-test2-labelled.csv $\\Rightarrow$ The above two files combined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>298</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>277</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>377</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>299</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>382</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>374</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>303</td>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>309</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>359</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>366</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>311</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>373</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>305</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>371</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Weight  Colour Label\n",
       "0      303       3     B\n",
       "1      370       1     A\n",
       "2      298       3     B\n",
       "3      277       3     B\n",
       "4      377       4     A\n",
       "5      299       3     B\n",
       "6      382       1     A\n",
       "7      374       4     A\n",
       "8      303       4     B\n",
       "9      309       3     B\n",
       "10     359       1     A\n",
       "11     366       1     A\n",
       "12     311       3     B\n",
       "13     302       3     B\n",
       "14     373       4     A\n",
       "15     305       3     B\n",
       "16     371       3     A"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us first read the data from the file and do a quick visualization\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"01-train.csv\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d8e7ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apples = train[train.Label == \"A\"]\n",
    "bananas = train[train.Label == \"B\"]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(apples.Weight, apples.Colour, \"ro\")\n",
    "plt.plot(bananas.Weight, bananas.Colour, \"y+\")\n",
    "plt.xlabel(\"Weight -- in grams\")\n",
    "plt.ylabel(\"Colour -- r-o-y-g-b-p\")\n",
    "plt.legend([\"Apples\", \"Bananas\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  see that similar fruits come close in the feature (weight, color) space? Now let us plot one sample data given in black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d8db400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(apples.Weight, apples.Colour, \"ro\")\n",
    "plt.plot(bananas.Weight, bananas.Colour, \"y+\")\n",
    "plt.xlabel(\"Weight -- in grams\")\n",
    "plt.ylabel(\"Colour -- r-o-y-g-b-p\")\n",
    "plt.legend([\"Apples\", \"Bananas\"])\n",
    "plt.plot([373], [1], \"ko\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the visualization alone, we can infer that the unknown fruit is likely to be an apple. \n",
    "\n",
    "The job now is to instead of eyeballing it one at a time like above, use a kNN classifier with, say, $k = 3$ and using the *Euclidean* distance, to determine the correct label for the data in the file \"01-test1.csv\" that has 30 data points. \n",
    "\n",
    "Let us first write a distance function to calculate the *Euclidean* distance between two fruits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def dist(a, b):\n",
    "    sqSum = 0\n",
    "    for i in range(len(a)):\n",
    "        sqSum += (a[i] - b[i]) ** 2\n",
    "    return math.sqrt(sqSum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us write code to find the $k$ nearest neighbours of a given fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN(k, train, given):\n",
    "    distances = []\n",
    "    for t in train.values:              \n",
    "        # loop over all training samples\n",
    "        distances.append((dist(t[:2], given), t[2])) \n",
    "        # compute and store distances with respect to each training sample\n",
    "    distances.sort()            \n",
    "    return distances[:k]    # return first k samples = nearest  k distances to the given sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2.8284271247461903, 'A'), (3.0, 'A'), (3.0, 'A')]\n",
      "[(2.8284271247461903, 'A'), (3.0, 'A'), (3.0, 'A'), (3.1622776601683795, 'A'), (5.0, 'A')]\n"
     ]
    }
   ],
   "source": [
    "print(kNN(3, train, (373, 1)))\n",
    "print(kNN(5, train, (373, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the 3 (and 5) nearest neighbours of the fruit with the characteristics (373, 1) are all Apples -- label 1; which is what we visually saw when we plotted the point as a black spot in the chart. Of course we need to write another function to get this attribute rather than read, so we have written a function for that. We have used collections.Counter, which is a very useful python library. More detail are at:\n",
    "\n",
    " * https://docs.python.org/3/library/collections.html#collections.Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A', 4)\n",
      "('A', 5)\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "def kNNmax(k, train, given):\n",
    "    tally = collections.Counter()\n",
    "    for nn in kNN(k, train, given):\n",
    "        tally.update(nn[-1])\n",
    "    return tally.most_common(1)[0]\n",
    "\n",
    "\n",
    "\n",
    "print(kNNmax(5, train, (340, 1)))\n",
    "print(kNNmax(7, train, (340, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that of the five nearest neighbours to (340, 1) four are Apples and of the seven nearest, five are Apples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us load the test data and find the labels for all of them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 318.1    3. ] B\n",
      "[ 293.8    3. ] B\n",
      "[ 277.3    2. ] B\n",
      "[ 324.2    4. ] B\n",
      "[ 327.    2.] B\n",
      "[ 281.5    3. ] B\n",
      "[ 386.8    1. ] A\n",
      "[ 377.8    2. ] A\n",
      "[ 401.1    1. ] A\n",
      "[ 399.5    1. ] A\n",
      "[ 387.3    1. ] A\n",
      "[ 361.9    2. ] A\n",
      "[ 293.6    3. ] B\n",
      "[ 309.1    3. ] B\n",
      "[ 276.2    3. ] B\n",
      "[ 303.3    3. ] B\n",
      "[ 274.6    3. ] B\n",
      "[ 327.2    3. ] B\n",
      "[ 274.    3.] B\n",
      "[ 269.2    3. ] B\n",
      "[ 265.1    3. ] B\n",
      "[ 300.7    3. ] B\n",
      "[ 282.1    3. ] B\n",
      "[ 274.6    3. ] B\n",
      "[ 357.2    4. ] A\n",
      "[ 405.7    4. ] A\n",
      "[ 377.8    4. ] A\n",
      "[ 401.7    4. ] A\n",
      "[ 342.2    4. ] A\n",
      "[ 397.4    4. ] A\n"
     ]
    }
   ],
   "source": [
    "#print(train)\n",
    "import math\n",
    "testData1 = pd.read_csv('01-test1.csv').values\n",
    "for t in testData1:\n",
    "    print(t, kNNmax(3, train, t)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us count how many are correct, instead of displaying the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 are correct\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testData = pd.read_csv('01-test1.csv').values\n",
    "testResults = pd.read_csv('01-test1-labels.csv').values.flatten()\n",
    "results = []\n",
    "for i, t in enumerate(testData):\n",
    "    results.append(kNNmax(3, train, t)[0] == testResults[i])\n",
    "print(results.count(True), \"are correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** :: Find the accuracy of your prediction -- percentage of the samples that are correctly predicted.\n",
    "\n",
    "**Exercise 2** :: Predict the labels for the larger file \"01-test2.csv\" that has 72 data points\n",
    "\n",
    "Note that with 17 samples we are predicting (rather accurately) the labels on a larger level\n",
    "\n",
    "**Exercise 3** :: Find the accuracy of the prediction by comparing with \"01-test2-labels.csv\" \n",
    "\n",
    "**Exercise 4** :: Repeat the above experiment with $k = 5$ and $k = 7$. Explain which $k$ is better and why?\n",
    "\n",
    "**Exercise 5** :: Repeat the above experiment with $k = 17$. What do you think is happening?\n",
    "\n",
    "**Exercise 6** :: If the weights are in Kgs, that is divide all of the data in weights column by 1000, what is the accuracy for $k = 3$\n",
    "\n",
    "**Exercise 7** :: Modify the distance function to ignore the colour feature. Calculate the accuracy on \"01-test1.csv\"\n",
    "\n",
    "**Exercise 8** :: If we used the square of the Euclidean distance, for the distance fuction does it affect the accuracy?\n",
    "\n",
    "**Exercise 9** :: If we use the sum of the absolute differences, as the distance metric instead of the Euclidean, how does that affect the accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Solution 1 ** :: Find the accuracy of your prediction -- percentage of the samples that are correctly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 are correct\n",
      "Percentage Accuracy = 100.0 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testData = pd.read_csv('01-test1.csv').values\n",
    "testResults = pd.read_csv('01-test1-labels.csv').values.flatten()\n",
    "results = []\n",
    "for i, t in enumerate(testData):\n",
    "    results.append(kNNmax(3, train, t)[0] == testResults[i])\n",
    "print(results.count(True), \"are correct\")\n",
    "print('Percentage Accuracy =', results.count(True) / len(testData) *100.0 , '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Solution 2 ** :: Predict the labels for the larger file \"01-test2.csv\" that has 72 data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 318.1    3. ] --> B\n",
      "[ 293.8    3. ] --> B\n",
      "[ 277.3    2. ] --> B\n",
      "[ 324.2    4. ] --> B\n",
      "[ 327.    2.] --> B\n",
      "[ 281.5    3. ] --> B\n",
      "[ 386.8    1. ] --> A\n",
      "[ 377.8    2. ] --> A\n",
      "[ 401.1    1. ] --> A\n",
      "[ 399.5    1. ] --> A\n",
      "[ 387.3    1. ] --> A\n",
      "[ 361.9    2. ] --> A\n",
      "[ 293.6    3. ] --> B\n",
      "[ 309.1    3. ] --> B\n",
      "[ 276.2    3. ] --> B\n",
      "[ 303.3    3. ] --> B\n",
      "[ 274.6    3. ] --> B\n",
      "[ 327.2    3. ] --> B\n",
      "[ 274.    3.] --> B\n",
      "[ 269.2    3. ] --> B\n",
      "[ 265.1    3. ] --> B\n",
      "[ 300.7    3. ] --> B\n",
      "[ 282.1    3. ] --> B\n",
      "[ 274.6    3. ] --> B\n",
      "[ 357.2    4. ] --> A\n",
      "[ 405.7    4. ] --> A\n",
      "[ 377.8    4. ] --> A\n",
      "[ 401.7    4. ] --> A\n",
      "[ 342.2    4. ] --> A\n",
      "[ 397.4    4. ] --> A\n"
     ]
    }
   ],
   "source": [
    "#print(train)\n",
    "testData2 = pd.read_csv('01-test2.csv').values\n",
    "results2 = []\n",
    "for i,t in enumerate(testData):\n",
    "    print (t, '-->',  kNNmax(3,train,t)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Solution 3** :: Find the accuracy of the prediction by comparing with \"01-test2-labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 are correct\n",
      "Percentage Accuracy = 100.0 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "testData = pd.read_csv('01-test2.csv').values\n",
    "testResults = pd.read_csv('01-test2-labels.csv').values.flatten()\n",
    "results = []\n",
    "for i, t in enumerate(testData):\n",
    "    results.append(kNNmax(3, train, t)[0] == testResults[i])\n",
    "print(results.count(True), \"are correct\")\n",
    "print('Percentage Accuracy =', results.count(True) / len(testData) *100.0 , '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution 4 ** :: Repeat the above experiment with  k=5 k=5  and  k=7 k=7 . Explain which  kk  is better and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 are correct\n",
      "Percentage Accuracy = 100.0 %\n"
     ]
    }
   ],
   "source": [
    "testData = pd.read_csv('01-test2.csv').values\n",
    "testResults = pd.read_csv('01-test2-labels.csv').values.flatten()\n",
    "results = []\n",
    "for i, t in enumerate(testData):\n",
    "    results.append(kNNmax(5, train, t)[0] == testResults[i])\n",
    "print(results.count(True), \"are correct\")\n",
    "print('Percentage Accuracy =', results.count(True) / len(testData) *100.0 , '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 are correct\n",
      "Percentage Accuracy = 100.0 %\n"
     ]
    }
   ],
   "source": [
    "testData = pd.read_csv('01-test2.csv').values\n",
    "testResults = pd.read_csv('01-test2-labels.csv').values.flatten()\n",
    "results = []\n",
    "for i, t in enumerate(testData):\n",
    "    results.append(kNNmax(7, train, t)[0] == testResults[i])\n",
    "print(results.count(True), \"are correct\")\n",
    "print('Percentage Accuracy =', results.count(True) / len(testData) *100.0 , '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Solution  5 ** :: Repeat the above experiment with  k=17k=17 . What do you think is happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 are correct\n",
      "Percentage Accuracy = 50.0 %\n"
     ]
    }
   ],
   "source": [
    "testData = pd.read_csv('01-test2.csv').values\n",
    "testResults = pd.read_csv('01-test2-labels.csv').values.flatten()\n",
    "results = []\n",
    "for i, t in enumerate(testData):\n",
    "    results.append(kNNmax(17, train, t)[0] == testResults[i])\n",
    "print(results.count(True), \"are correct\")\n",
    "print('Percentage Accuracy =', results.count(True) / len(testData) *100.0 , '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Solution 6 ** :: If the weights are in Kgs, that is divide all of the data in weights column by 1000, what is the accuracy for  k=3k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gramToKG(gram):\n",
    "    return float(gram) / 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 are correct\n",
      "Percentage Accuracy = 60.0 %\n"
     ]
    }
   ],
   "source": [
    "testData = pd.read_csv('01-test1.csv', converters={\"Weight\":gramToKG}).values\n",
    "testResults = pd.read_csv('01-test1-labels.csv').values.flatten()\n",
    "results = []\n",
    "for i, t in enumerate(testData):\n",
    "    results.append(kNNmax(3, train, t)[0] == testResults[i])\n",
    "print(results.count(True), \"are correct\")\n",
    "print('Percentage Accuracy =', results.count(True) / len(testData) *100.0 , '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Solution 7 **:: Modify the distance function to ignore the colour feature. Calculate the accuracy on \"01-test1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def dist(a, b):\n",
    "    sqSum = 0\n",
    "    for i in range(len(a)-1):\n",
    "        sqSum += (a[i] - b[i]) ** 2\n",
    "    return math.sqrt(sqSum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 are correct\n",
      "Percentage Accuracy = 100.0 %\n"
     ]
    }
   ],
   "source": [
    "testData = pd.read_csv('01-test1.csv').values\n",
    "testResults = pd.read_csv('01-test1-labels.csv').values.flatten()\n",
    "results = []\n",
    "for i, t in enumerate(testData):\n",
    "    results.append(kNNmax(3, train, t)[0] == testResults[i])\n",
    "print(results.count(True), \"are correct\")\n",
    "print('Percentage Accuracy =', results.count(True) / len(testData) *100.0 , '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Solution 8 ** :: If we used the square of the Euclidean distance, for the distance fuction does it affect the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def dist(a, b):\n",
    "    sqSum = 0\n",
    "    for i in range(len(a)):\n",
    "        sqSum += (a[i] - b[i]) ** 2\n",
    "    return sqSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 are correct\n",
      "Percentage Accuracy = 100.0 %\n"
     ]
    }
   ],
   "source": [
    "testData = pd.read_csv('01-test1.csv').values\n",
    "testResults = pd.read_csv('01-test1-labels.csv').values.flatten()\n",
    "results = []\n",
    "for i, t in enumerate(testData):\n",
    "    results.append(kNNmax(3, train, t)[0] == testResults[i])\n",
    "print(results.count(True), \"are correct\")\n",
    "print('Percentage Accuracy =', results.count(True) / len(testData) *100.0 , '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Solution 9 ** :: If we use the sum of the absolute differences, as the distance metric instead of the Euclidean, how does that affect the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgment\n",
    "This experiment is based on the blog post http://www.jiaaro.com/KNN-for-humans. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In the above experiment, we find that a simple nearest neighbour method can successfully predict labels with a small number of labelled examples. But we also see that the results can go really wrong if we make some wrong choices (like weight in Kg, or a very large K). This should remind you about the practical expertise and experimental skills that will become equally important as we move forward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
