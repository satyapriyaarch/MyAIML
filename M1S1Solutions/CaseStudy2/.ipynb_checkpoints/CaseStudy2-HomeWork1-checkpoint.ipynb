{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1\n",
    "## Case Study 2\n",
    "### Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source\n",
    "\n",
    "* movie-train.csv\n",
    "\n",
    "* movie-test.csv\n",
    "\n",
    "These have been taken (and modified) from:\n",
    "http://kevinmolloy.info/teaching/cs504_2017Fall/\n",
    "\n",
    "This is a small subset of the original movielens dataset.\n",
    "https://grouplens.org/datasets/movielens/\n",
    "\n",
    "\n",
    "#### Objective\n",
    "To use kNN as a kind of a recommendation/prediction for movies.\n",
    "\n",
    "#### Datasets\n",
    "\n",
    "As discussed in class, you will build your model using the training data. To test your model, you will calculate predictions for each entry in the test set (a userID/movieID pair), and since you know the real rating, you can compute the difference between the two, and determine how well your method performs, as an additional exercise. In this exercise we only consider if a user has seen or not seen -- irrespective of the rating. \n",
    "\n",
    "In other words if a userId, movieId, rating line exists, then the user has seen that movie. \n",
    "\n",
    "\n",
    "### Description\n",
    "\n",
    "Consider the problem of recommending movies to users. We have M Users and N Movies. \n",
    "Now, we want to predict whether a given test user $x$ will watch movie $y$.\n",
    "\n",
    "User $x$ has seen and not seen few movies in the past. We will use $x$'s movie watching history as a feature for our recommendation system.\n",
    "\n",
    "We will use KNN to find the K nearest neighbour users (users with similar taste) to $x$, and make predictions based on their entries for movie $y$.\n",
    "\n",
    "A user either had seen the movie (1) or not seen the movie (0). We can represent this as a matrix of size M×N. (M rows and N columns). We have actually used a dictionary with the keys userId and movieId to represent this matrix.\n",
    "\n",
    "Each element of the matrix is either zero or one. If (u, m) entry in this matrix is 1, then the $u^{th}$ user has seen the movie $m$.\n",
    "#### Training set\n",
    "M×N binary matrix indicating seen/not-seen.\n",
    "#### Test set: \n",
    "L test cases with $(x, y)$ pairs. $x$ is N-dimensional binary vector with missing $y^{th}$ entry - which we want to predict.\n",
    "\n",
    "Now, we want to predict whether a given test user x will watch movie y.\n",
    "\n",
    "User x has seen and not seen few movies in the past. We will use x's movie watching history as feature for our recommendation system.\n",
    "**Exercise 1** :: Write a function to compute euclidean distance between two users for all entries except the missing $y^{th}$ entry.\n",
    "\n",
    "We will use KNN to find the K nearest neighbour users (users with similar taste) to x, and make predictions based on their entries for movie y.\n",
    "\n",
    "We have given the code for Cosine distance, when computing nearest neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rated = pd.read_csv(\"movie-train.csv\", converters={\"userId\":int, \"movieId\":int})\n",
    "rated.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6073550"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userCount = max(rated.userId)\n",
    "movieCount = max(rated.movieId)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seen = {}\n",
    "for x in rated.values:\n",
    "    seen[(int(x[0]), int(x[1]))] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allUsersMovies = [(u,m) for u in range(userCount) for m in range(movieCount)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in allUsersMovies:\n",
    "    if x not in seen:\n",
    "        seen[x] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the data loaded into a dictionary, let us recast the distance function to use it. Given two users, $u_1$ and $u_2$, for a movie $m$, we must ignore the entries for $m$ for every other user while computing distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is actually the cosine distance\n",
    "def distance(u1, u2, mx):\n",
    "    d = 0 - seen[(u1, x)] * seen[(u2, mx)]\n",
    "    for m in range(movieCount):\n",
    "        d += seen[(u1, m)] * seen[(u2, m)]\n",
    "    return d\n",
    "\n",
    "def kNN(k, givenUser, givenMovie):\n",
    "    distances = []\n",
    "    for u in range(userCount):\n",
    "        if u != givenUser:\n",
    "            distances.append([distance(u, givenUser, givenMovie), u])\n",
    "    distances.sort()\n",
    "    distances.reverse() ## Because cosine distances mean higher = closer\n",
    "    return distances[:k] \n",
    "\n",
    "def prediction(k, givenUser, givenMovie):\n",
    "    neighbours = kNN(k, givenUser, givenMovie)\n",
    "    howmanySaw = sum([seen[(u, givenMovie)] for d, u in neighbours])\n",
    "    return 2 * howmanySaw > k\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** :: Verify the above code and check if it works\n",
    "\n",
    "**Exercise 2** :: Change the distance function to compute Euclidean, and see if the prediction changes. Remember to modify the kNN function to pick the smallest distances: do not reverse()!\n",
    "\n",
    "**Exercise 3** :: Change the distance function to compute Manhattan, and see if the prediction changes. Remember to modify the kNN function to pick the smallest distances: do not reverse()!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
